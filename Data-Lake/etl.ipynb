{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, monotonically_increasing_id\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format, dayofweek\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Sparkify').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = './data/'\n",
    "output_data = './data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Song Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_latitude: double (nullable = true)\n",
      " |-- artist_location: string (nullable = true)\n",
      " |-- artist_longitude: double (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- num_songs: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "song_data = input_data + 'song_data/*/*/*/*.json'\n",
    "    \n",
    "song_schema = StructType([\n",
    "    StructField(\"artist_id\", StringType()),\n",
    "    StructField(\"artist_latitude\", DoubleType()),\n",
    "    StructField(\"artist_location\", StringType()),\n",
    "    StructField(\"artist_longitude\", DoubleType()),\n",
    "    StructField(\"artist_name\", StringType()),\n",
    "    StructField(\"duration\", DoubleType()),\n",
    "    StructField(\"num_songs\", IntegerType()),\n",
    "    StructField(\"title\", StringType()),\n",
    "    StructField(\"year\", IntegerType())\n",
    "])\n",
    "    \n",
    "df = spark.read.json(song_data, schema=song_schema)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+----+---------+-----------+\n",
      "|               title|         artist_id|year| duration|    song_id|\n",
      "+--------------------+------------------+----+---------+-----------+\n",
      "|               Intro|AR558FS1187FB45658|2003| 75.67628|51539607552|\n",
      "|Setting Fire to S...|ARMAC4T1187FB3FA4C|2004|207.77751|68719476736|\n",
      "|Kutt Free (DJ Vol...|ARNNKDK1187B98BBD5|   0|407.37914|68719476737|\n",
      "|Get Your Head Stu...|AREDL271187FB40F44|   0| 45.66159|77309411328|\n",
      "|     Amor De Cabaret|ARKRRTF1187B9984DA|   0|177.47546|94489280512|\n",
      "+--------------------+------------------+----+---------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "song_table = df.select('title', 'artist_id', 'year', 'duration').dropDuplicates()\\\n",
    "                .withColumn('song_id', monotonically_increasing_id())\n",
    "song_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_table.write.parquet(output_data + 'songs/', mode='overwrite', partitionBy=['year', 'artist_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------+---------------+---------------+----------------+\n",
      "|         artist_id| artist_name|artist_location|artist_latitude|artist_longitude|\n",
      "+------------------+------------+---------------+---------------+----------------+\n",
      "|ARPBNLO1187FB3D52F|    Tiny Tim|   New York, NY|       40.71455|       -74.00712|\n",
      "|ARBEBBY1187B9B43DB|   Tom Petty|Gainesville, FL|           null|            null|\n",
      "|AR0IAWL1187B9A96D0|Danilo Perez|         Panama|         8.4177|       -80.11278|\n",
      "|ARMBR4Y1187B9990EB|David Martin|California - SF|       37.77916|      -122.42005|\n",
      "|ARD0S291187B9B7BF5|     Rated R|           Ohio|           null|            null|\n",
      "+------------------+------------+---------------+---------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artist_table = df.select(\"artist_id\",\"artist_name\",\"artist_location\",\"artist_latitude\",\"artist_longitude\").dropDuplicates()\n",
    "artist_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_table.write.parquet(output_data + 'artists/', mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Log Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data = input_data + 'log-data/'\n",
    "\n",
    "df = spark.read.json(log_data).drop_duplicates()\n",
    "\n",
    "df = df.filter(df.page == 'NextSong')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------+------+-----+\n",
      "|userId|firstName|lastName|gender|level|\n",
      "+------+---------+--------+------+-----+\n",
      "|    98|   Jordyn|  Powell|     F| free|\n",
      "|    34|   Evelin|   Ayala|     F| free|\n",
      "|    85|  Kinsley|   Young|     F| paid|\n",
      "|    38|   Gianna|   Jones|     F| free|\n",
      "|    85|  Kinsley|   Young|     F| free|\n",
      "+------+---------+--------+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_fields = [\"userId\", \"firstName\", \"lastName\", \"gender\", \"level\"]\n",
    "users_table = df.selectExpr(users_fields).drop_duplicates()\n",
    "users_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_table.write.parquet(output_data + 'users/', mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+----+---+----+-----+----+-------+\n",
      "|           ts|          start_time|hour|day|week|month|year|weekday|\n",
      "+-------------+--------------------+----+---+----+-----+----+-------+\n",
      "|1542394784796|2018-11-16 18:59:...|  18| 16|  46|   11|2018|      6|\n",
      "|1543219406796|2018-11-26 08:03:...|   8| 26|  48|   11|2018|      2|\n",
      "|1542695612796|2018-11-20 06:33:...|   6| 20|  47|   11|2018|      3|\n",
      "|1543026602796|2018-11-24 02:30:...|   2| 24|  47|   11|2018|      7|\n",
      "|1542276456796|2018-11-15 10:07:...|  10| 15|  46|   11|2018|      5|\n",
      "+-------------+--------------------+----+---+----+-----+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_timestamp = udf(lambda x: datetime.utcfromtimestamp(int(x) / 1000), TimestampType())\n",
    "df = df.withColumn('start_time', get_timestamp('ts'))\n",
    "\n",
    "time_table = df.withColumn(\"hour\",hour(\"start_time\"))\\\n",
    "                .withColumn(\"day\",dayofmonth(\"start_time\"))\\\n",
    "                .withColumn(\"week\",weekofyear(\"start_time\"))\\\n",
    "                .withColumn(\"month\",month(\"start_time\"))\\\n",
    "                .withColumn(\"year\",year(\"start_time\"))\\\n",
    "                .withColumn(\"weekday\",dayofweek(\"start_time\"))\\\n",
    "                .select(\"ts\",\"start_time\",\"hour\", \"day\", \"week\", \"month\", \"year\", \"weekday\").drop_duplicates()\n",
    "\n",
    "time_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_table.write.parquet(output_data + 'time_table/', mode='overwrite', partitionBy=['year', 'month'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Songplays Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in song data to use for songplays table\n",
    "song_df = spark.read\\\n",
    "                .format(\"parquet\")\\\n",
    "                .option(\"basePath\", os.path.join(output_data, \"songs/\"))\\\n",
    "                .load(os.path.join(output_data, \"songs/*/*/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract columns from joined song and log datasets to create songplays table\n",
    "songplays_table = df.join(song_df, df.song == song_df.title, how='inner')\\\n",
    "                    .select(monotonically_increasing_id().alias(\"songplay_id\"), col(\"start_time\"),\n",
    "                            col(\"userId\").alias(\"user_id\"), \"level\", \"song_id\", \"artist_id\", \n",
    "                            col(\"sessionId\").alias(\"session_id\"), \"location\", col(\"userAgent\").alias(\"user_agent\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "songplays_table = songplays_table.join(time_table, songplays_table.start_time == time_table.start_time, how=\"inner\")\\\n",
    "                        .select(\"songplay_id\", songplays_table.start_time, \"user_id\", \"level\", \"song_id\", \"artist_id\", \n",
    "                                \"session_id\", \"location\", \"user_agent\", \"year\", \"month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+-------+-----+-------------+------------------+----------+--------------------+--------------------+----+-----+\n",
      "|  songplay_id|          start_time|user_id|level|      song_id|         artist_id|session_id|            location|          user_agent|year|month|\n",
      "+-------------+--------------------+-------+-----+-------------+------------------+----------+--------------------+--------------------+----+-----+\n",
      "| 601295421440|2018-11-27 22:35:...|     80| paid|  51539607552|AR558FS1187FB45658|       992|Portland-South Po...|\"Mozilla/5.0 (Mac...|2018|   11|\n",
      "| 652835028992|2018-11-19 09:14:...|     24| paid|  51539607552|AR558FS1187FB45658|       672|Lake Havasu City-...|\"Mozilla/5.0 (Win...|2018|   11|\n",
      "| 790273982464|2018-11-21 21:56:...|     15| paid|1348619730944|AR5KOSW1187FB35FF4|       818|Chicago-Napervill...|\"Mozilla/5.0 (X11...|2018|   11|\n",
      "|1254130450432|2018-11-14 05:06:...|     10| free|  51539607552|AR558FS1187FB45658|       484|Washington-Arling...|\"Mozilla/5.0 (Mac...|2018|   11|\n",
      "+-------------+--------------------+-------+-----+-------------+------------------+----------+--------------------+--------------------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songplays_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write songplays table to parquet files partitioned by year and month\n",
    "songplays_table.drop_duplicates().write.parquet(os.path.join(output_data, \"songplays/\"), mode=\"overwrite\", partitionBy=[\"year\",\"month\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
